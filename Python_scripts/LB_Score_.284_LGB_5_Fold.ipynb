{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import *\n",
    "from sklearn.model_selection import KFold\n",
    "import gc\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.54250812531\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train = pd.read_csv(\"/home/saurabhg/PuertoSergo/train.csv\")\n",
    "test = pd.read_csv(\"/home/saurabhg/PuertoSergo/test.csv\")\n",
    "print(time.time()-start)\n",
    " \n",
    "y = train['target']\n",
    "testid= test['id'].values\n",
    "\n",
    "train.drop(['id','target'],axis=1,inplace=True)\n",
    "test.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.061964035\n",
      "('Init Shape: ', (595212, 39))\n",
      "('After Shape: ', (595212, 136))\n",
      "('Init Shape: ', (892816, 39))\n",
      "('After Shape: ', (892816, 136))\n",
      "77.6997139454\n"
     ]
    }
   ],
   "source": [
    "### Drop calc\n",
    "\n",
    "start = time.time()\n",
    "unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "train = train.drop(unwanted, axis=1)  \n",
    "test = test.drop(unwanted, axis=1)\n",
    "\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "### Great Recovery from Pascal's materpiece\n",
    "#train['ps_reg_03_square'] = train['ps_reg_03']*train['ps_reg_03']\n",
    "#test['ps_reg_03_square'] = test['ps_reg_03']*test['ps_reg_03']\n",
    "#train['ps_car_14_square'] = train['ps_car_14']*train['ps_car_14']\n",
    "#test['ps_car_14_square'] = test['ps_car_14']*test['ps_car_14']\n",
    "def recon(reg):\n",
    "    integer = int(np.round((40*reg)**2)) \n",
    "    for a in range(32):\n",
    "        if (integer - a) % 31 == 0:\n",
    "            A = a\n",
    "    M = (integer - A)//31\n",
    "    return A, M\n",
    "train['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "train['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "train['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "train['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "test['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "test['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "test['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "test['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "\n",
    "print(time.time()-start)\n",
    "\n",
    "\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "### Froza's baseline\n",
    "\n",
    "d_median = train.median(axis=0)\n",
    "d_mean = train.mean(axis=0)\n",
    "d_skew = train.skew(axis=0)\n",
    "one_hot = {c: list(train[c].unique()) for c in train.columns if c not in ['id','target']}\n",
    "\n",
    "def transform_df(df):\n",
    "    df = pd.DataFrame(df)\n",
    "    dcol = [c for c in df.columns if c not in ['id','target']]\n",
    "    df['ps_car_13_x_ps_reg_03'] = df['ps_car_13'] * df['ps_reg_03']\n",
    "    df['negative_one_vals'] = np.sum((df[dcol]==-1).values, axis=1)\n",
    "    for c in dcol:\n",
    "        if '_bin' not in c: #standard arithmetic\n",
    "            df[c+str('_median_range')] = (df[c].values > d_median[c]).astype(np.int)\n",
    "            df[c+str('_mean_range')] = (df[c].values > d_mean[c]).astype(np.int)\n",
    "\n",
    "    for c in one_hot:\n",
    "        if len(one_hot[c])>2 and len(one_hot[c]) < 7:\n",
    "            for val in one_hot[c]:\n",
    "                df[c+'_oh_' + str(val)] = (df[c].values == val).astype(np.int)\n",
    "    return df\n",
    "\n",
    "def multi_transform(df, map=transform_df):\n",
    "    print('Init Shape: ', df.shape)\n",
    "    p = Pool(cpu_count())\n",
    "    df = p.map(transform_df, np.array_split(df, cpu_count()))\n",
    "    df = pd.concat(df, axis=0, ignore_index=True).reset_index(drop=True)\n",
    "    p.close(); p.join()\n",
    "    print('After Shape: ', df.shape)\n",
    "    return df\n",
    "\n",
    "train = multi_transform(train)\n",
    "test = multi_transform(test)\n",
    "\n",
    "print(time.time()-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "\n",
    "@jit\n",
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_lgb(act, preds):\n",
    "#    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(act, preds)\n",
    "    return 'gini', gini_score,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 5000\n",
    "OPTIMIZE_ROUNDS = True\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  \n",
    "f_cats = [f for f in train.columns if \"_cat\" in f]\n",
    "# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n",
    "#       I will get lots of information to make my own judgment.  You should probably\n",
    "#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "n_estimators = 1000\n",
    "folds = KFold(n_splits=n_splits, shuffle=True, random_state=1) \n",
    "imp_df = np.zeros((len(train.columns), n_splits))\n",
    "oof = np.empty(len(train))\n",
    "sub_preds = np.zeros((len(test),n_splits))\n",
    "increase = False\n",
    "np.random.seed(0)\n",
    "params = {'eta': 0.025, 'max_depth': 4, \n",
    "          'subsample': 0.9, 'colsample_bytree': 0.7, \n",
    "          'colsample_bylevel':0.7,\n",
    "          'min_child_weight':100,\n",
    "          'alpha':10,\n",
    "          'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.261915\tvalid_1's gini: 0.247047\n",
      "[200]\ttraining's gini: 0.295073\tvalid_1's gini: 0.271944\n",
      "[300]\ttraining's gini: 0.316138\tvalid_1's gini: 0.282308\n",
      "[400]\ttraining's gini: 0.330736\tvalid_1's gini: 0.285496\n",
      "[500]\ttraining's gini: 0.343112\tvalid_1's gini: 0.286666\n",
      "Early stopping, best iteration is:\n",
      "[487]\ttraining's gini: 0.341676\tvalid_1's gini: 0.286977\n",
      "Fold  1 : 0.286927 @1000 / best score is 537.000000 @ 486\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.264232\tvalid_1's gini: 0.250873\n",
      "[200]\ttraining's gini: 0.29724\tvalid_1's gini: 0.269681\n",
      "[300]\ttraining's gini: 0.317898\tvalid_1's gini: 0.277219\n",
      "[400]\ttraining's gini: 0.332754\tvalid_1's gini: 0.280248\n",
      "[500]\ttraining's gini: 0.344772\tvalid_1's gini: 0.281691\n",
      "[600]\ttraining's gini: 0.355662\tvalid_1's gini: 0.281759\n",
      "Early stopping, best iteration is:\n",
      "[564]\ttraining's gini: 0.351911\tvalid_1's gini: 0.281985\n",
      "Fold  2 : 0.281951 @1000 / best score is 614.000000 @ 563\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.266406\tvalid_1's gini: 0.240573\n",
      "[200]\ttraining's gini: 0.299963\tvalid_1's gini: 0.26086\n",
      "[300]\ttraining's gini: 0.321441\tvalid_1's gini: 0.270987\n",
      "[400]\ttraining's gini: 0.336078\tvalid_1's gini: 0.273939\n",
      "[500]\ttraining's gini: 0.348413\tvalid_1's gini: 0.274753\n",
      "Early stopping, best iteration is:\n",
      "[510]\ttraining's gini: 0.349507\tvalid_1's gini: 0.274882\n",
      "Fold  3 : 0.274810 @1000 / best score is 560.000000 @ 509\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.261136\tvalid_1's gini: 0.267507\n",
      "[200]\ttraining's gini: 0.293131\tvalid_1's gini: 0.286768\n",
      "[300]\ttraining's gini: 0.314533\tvalid_1's gini: 0.294499\n",
      "[400]\ttraining's gini: 0.329849\tvalid_1's gini: 0.297212\n",
      "[500]\ttraining's gini: 0.34219\tvalid_1's gini: 0.29806\n",
      "[600]\ttraining's gini: 0.353389\tvalid_1's gini: 0.298646\n",
      "[700]\ttraining's gini: 0.364018\tvalid_1's gini: 0.299109\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttraining's gini: 0.367551\tvalid_1's gini: 0.299184\n",
      "Fold  4 : 0.299152 @1000 / best score is 788.000000 @ 737\n",
      "Train until valid scores didn't improve in 50 rounds.\n",
      "[100]\ttraining's gini: 0.266115\tvalid_1's gini: 0.245621\n",
      "[200]\ttraining's gini: 0.29698\tvalid_1's gini: 0.267595\n",
      "[300]\ttraining's gini: 0.316982\tvalid_1's gini: 0.277543\n",
      "[400]\ttraining's gini: 0.331757\tvalid_1's gini: 0.282929\n",
      "[500]\ttraining's gini: 0.343632\tvalid_1's gini: 0.284799\n",
      "[600]\ttraining's gini: 0.354637\tvalid_1's gini: 0.286068\n",
      "[700]\ttraining's gini: 0.364554\tvalid_1's gini: 0.286909\n",
      "Early stopping, best iteration is:\n",
      "[703]\ttraining's gini: 0.364858\tvalid_1's gini: 0.286983\n",
      "Fold  5 : 0.286965 @1000 / best score is 753.000000 @ 702\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a7021daaa5ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m              best_round))\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Full OOF score : %.6f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgini_normalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(y, y)):\n",
    "    trn_dat, trn_tgt = train.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    val_dat, val_tgt = train.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "    clf = lgb.LGBMModel(n_estimators=n_estimators,\n",
    "                        num_leaves=20,\n",
    "   #                     boosting_type = 'dart',\n",
    "                        objective=\"binary\",\n",
    "                        learning_rate=.025, \n",
    "                        subsample=.9, \n",
    "                        colsample_bytree=.7,\n",
    "         #               min_split_gain = .77,\n",
    "        #                min_child_samples= 500,\n",
    "         #               is_unbalance = True,\n",
    "                        min_child_weight =100,\n",
    "                        reg_alpha=4,\n",
    "          #              reg_lambda=2,\n",
    "                      #  nthread=2\n",
    "                       )\n",
    "    # Upsample during cross validation to avoid having the same samples\n",
    "    # in both train and validation sets\n",
    "    # Validation set is not up-sampled to monitor overfitting\n",
    "    if increase:\n",
    "        # Get positive examples\n",
    "        pos = pd.Series(trn_tgt == 1)\n",
    "        # Add positive examples\n",
    "        trn_dat = pd.concat([trn_dat, trn_dat.loc[pos]], axis=0)\n",
    "        trn_tgt = pd.concat([trn_tgt, trn_tgt.loc[pos]], axis=0)\n",
    "        # Shuffle data\n",
    "        idx = np.arange(len(trn_dat))\n",
    "        np.random.shuffle(idx)\n",
    "        trn_dat = trn_dat.iloc[idx]\n",
    "        trn_tgt = trn_tgt.iloc[idx]\n",
    "        \n",
    "    clf.fit(trn_dat, trn_tgt, \n",
    "            eval_set=[(trn_dat, trn_tgt), (val_dat, val_tgt)],\n",
    "            categorical_feature = f_cats,\n",
    "            eval_metric=gini_lgb,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=100)\n",
    "    # Find best round for validation setA\n",
    "    lgb_evals = clf.evals_result_[\"valid_1\"][\"gini\"]\n",
    "    #print(clf.evals_result_ )\n",
    "    # Keep feature importances\n",
    "    imp_df[:, fold_] = clf.feature_importances_\n",
    "    #Xgboost provides best round starting from 0 so it has to be incremented\n",
    "    best_round = np.argsort(lgb_evals)[::-1][0]\n",
    "\n",
    "    # Predict OOF and submission probas with the best round\n",
    "    oof[val_idx] = clf.predict(val_dat, num_iteration=best_round)\n",
    "    # Update submission\n",
    "    sub_preds[:, fold_] = clf.predict(test, num_iteration=best_round)\n",
    "\n",
    "    # Display results\n",
    "    print(\"Fold %2d : %.6f @%4d / best score is %.6f @%4d\"\n",
    "          % (fold_ + 1,\n",
    "             gini_normalized(val_tgt, oof[val_idx]),\n",
    "             n_estimators,\n",
    "             len(lgb_evals),\n",
    "             best_round))\n",
    "          \n",
    "print(\"Full OOF score : %.6f\" % gini_normalized(y, oof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02943459,  0.0249817 ,  0.02366248, ...,  0.03725916,\n",
       "        0.02179056,  0.03386809])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full OOF score : 0.285804\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = testid\n",
    "sub[\"target\"] =scipy.stats.hmean(sub_preds,axis=1)\n",
    "sub.to_csv(\"submission_10312017_LGB_.285805_5kfold.csv\", index=False, float_format=\"%.9f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
